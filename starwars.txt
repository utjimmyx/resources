---
title: "Exploring the New Star Wars Series – Andor Using Reddit Posts"
output: html_document
author: "Dr. Zhenning 'Jimmy' Xu, follow me on Twitter at https://twitter.com/MKTJimmyxu, on YouTube at https://www.youtube.com/@webdatax, or visit my website at https://github.com/utjimmyx"
date: "2025-04-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Disclaimer

All posts collected for this analysis are **sourced from the subreddit r/StarWars**. This analysis is conducted solely for **educational purposes**. No content is used for commercial gain, and all rights to original posts remain with their respective authors.

## Introduction

You might have tried to analyze social media data using tools offered by SproutSocial, Brand24, or Numerous.AI (see the reference section of my tutorial). What if I tell you that you can DIY for free? Yes, it is true!

Have you watched the new Star Wars series **Andor** recently? I am planning to watch it in May 2025. Before heading to the theater, I wanted to see what people are saying about it.

In this tutorial, I show you how Reddit discussions can be used to gauge people's opinions about Star Wars, particularly focusing on the new episode **Andor**, based on real-time conversations and fan reactions. By cleaning and analyzing this data, we can uncover key themes, sentiment trends, and recurring topics across the Star Wars community.

## For beginner-level R Users 
If you never used R or R Studio before, you might want to visit R for data science here for some basic refresher: https://r4ds.had.co.nz/. 

## Loading Data

First, let’s load the data that is scraped from the Sub-Reddit at (https://www.reddit.com/r/economy/) in April 2025. 

## Scraping Reddit data using R and the RedditExtractoR package in your desktop version of RStudio

## Load the free packages and Data

```{r}

# Load necessary libraries
library(tidyverse)
library(lubridate)
library(wordcloud)
library(wordcloud2)
library(tm)
library(sentimentr)
library(ggplot2)
library(tidytext)
library(tidyr)
library(DT)

# Read the data
reddit_data <- read.csv("starwars.csv", stringsAsFactors = FALSE)
head(reddit_data)
```

## Descriptive Analysis
```{r}
# Convert date_utc to proper date format
reddit_data$date <- as_datetime(reddit_data$date_utc)

# Basic summary statistics
summary(reddit_data$comments)

# Time series analysis - posts per day
daily_posts <- reddit_data %>%
  mutate(date = as.Date(date)) %>%
  count(date)


# Analyze comment engagement
ggplot(reddit_data, aes(x = comments)) +
  geom_histogram(bins = 30, fill = "steelblue") +
  labs(title = "Distribution of Comments on The Star Wars Series- Andor",
       x = "Number of Comments",
       y = "Count") +
  theme_minimal()

# Find most engaging posts (most comments)
top_posts <- reddit_data %>%
  arrange(desc(comments)) %>%
  select(date, title, comments) %>%
  head(10)
print(top_posts)

# Display as an interactive table with formatting options using the **DT** library
datatable(top_posts, 
          options = list(
            pageLength = 10,
            autoWidth = TRUE,
            columnDefs = list(list(
              targets = 1,
              width = '60%'
            )),
            dom = 'Bfrtip',
            buttons = c('copy', 'csv', 'excel')
          ),
          caption = htmltools::tags$caption(
            style = 'caption-side: top; text-align: center; font-size: 16px; font-weight: bold;',
            'Top 10 Most Engaging Reddit Posts'
          ),
          rownames = FALSE,
          filter = 'top',
          class = 'cell-border stripe hover'
) %>%
  formatDate('date', method = 'toLocaleDateString') %>%
  formatStyle('comments',
              background = styleColorBar(c(0, max(top_posts$comments)), 'lightblue'),
              backgroundSize = '100% 90%',
              backgroundRepeat = 'no-repeat',
              backgroundPosition = 'center')
```

## Word Frequency Analysis, Word Clouds, and Sentiment Analysis

```{r}

# Text analysis - create a corpus from post titles
corpus <- Corpus(VectorSource(reddit_data$title))
corpus <- corpus %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(tolower) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(stripWhitespace)

# Create document-term matrix
dtm <- DocumentTermMatrix(corpus)
freq <- colSums(as.matrix(dtm))
word_freq <- data.frame(word = names(freq), freq = freq)

# Plot most common words
word_freq %>%
  arrange(desc(freq)) %>%
  head(20) %>%
  ggplot(aes(x = reorder(word, freq), y = freq)) +
  geom_col(fill = "darkgreen") +
  coord_flip() +
  labs(title = "Most Common Words in Reddit Posts for the Star Wars Series- Andor",
       x = "Word",
       y = "Frequency") +
  theme_minimal()






# Text analysis - create a corpus from post titles
corpus <- Corpus(VectorSource(reddit_data$text))
corpus <- corpus %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(tolower) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(stripWhitespace)


# Create document-term matrix
dtm <- DocumentTermMatrix(corpus)
freq <- colSums(as.matrix(dtm))
word_freq <- data.frame(word = names(freq), freq = freq)

# Plot most common words
word_freq %>%
  arrange(desc(freq)) %>%
  head(30) %>%
  ggplot(aes(x = reorder(word, freq), y = freq)) +
  geom_col(fill = "darkgreen") +
  coord_flip() +
  labs(title = "Most Common Words in Reddit Post Text for the Star Wars Series – Andor ",
       x = "Word",
       y = "Frequency") +
  theme_minimal()

# Generate word cloud
set.seed(123)
wordcloud(words = word_freq$word, 
          freq = word_freq$freq, 
          max.words = 100,
          colors = brewer.pal(8, "Dark2"))

# Create the interactive word cloud
wordcloud2(data = word_freq, 
           size = 1,
           color = "random-dark",
           backgroundColor = "white",
           shape = "circle",
           rotateRatio = 0.3)


# NRC lexicon method on the cleaned data
sentiments <- word_freq %>%
  inner_join(get_sentiments("bing"), by = "word", relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE)

sentiments %>%
  ggplot(aes(x = sentiment, y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  labs(title = "Sentiment Analysis of Reddit Comments", x = "Sentiment", y = "Frequency")

```


## Conclusion

In this tutorial, we aim to explore public perceptions of the current Star Wars Series, Andor, using text data. Through data scraping, cleaning, and text analysis, we were able to capture real-time conversations and identify emerging economic concerns, sentiments, and trends.

While this approach cannot replace traditional economic data, it offers valuable complementary insights that reflect the lived experiences and opinions of individuals. 

Which analysis/graph did you like the best? Why? Feel free to follow me on Twitter at https://twitter.com/MKTJimmyxu, on YouTube at https://www.youtube.com/@webdatax, or visit my website at https://github.com/utjimmyx. 

## Reference:

- How to Do Reddit Sentiment Analysis? Example & Guide: https://brand24.com/blog/reddit-sentiment-analysis/ 

- Sproutsocial - Reddit sentiment analysis: https://sproutsocial.com/glossary/reddit-sentiment-analysis/

- Simple Step-by-Step Guide On Reddit Sentiment Analysis: https://numerous.ai/blog/reddit-sentiment-analysis 

- R for Data Science: https://r4ds.had.co.nz/

- Text Mining with R: https://www.tidytextmining.com/